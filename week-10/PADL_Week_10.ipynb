{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_DvC9pNqRLl"
   },
   "source": [
    "# PADL Practical Week 10: Deep generative models\n",
    "\n",
    "There's a lot in this week's practical. You don't necessarily need to do it all. Everyone should try exercise 2 as it is essential for the assessment. Masters students should also try exercise 4. Exercise 1 is useful for helping your understanding and the result is somewhat intriguing. Exercise 3 is fun as you get to create photorealistic images from prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5W-_dD-MicgZ"
   },
   "source": [
    "## 1. Adversarial perturbations\n",
    "\n",
    "You will start by creating an \"adversarial perturbation\" of an image in order to break a classifier. This means you will find a small offset that can be added to an image to change the class assigned to it by a classifier. We will do this using a pretrained LeNet for MNIST digit classification. You will need to look at the third video lecture for this week (or at least the slides). First, let's set up the network and load the pretrained weights. The code below will download the `LeNet_weights.pkl` file and then load it into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:21:53.578613Z",
     "start_time": "2024-04-30T13:21:52.151840Z"
    },
    "id": "Ladhs7M7lzCT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanbar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:17:55.369648Z",
     "start_time": "2024-04-30T13:17:55.247929Z"
    },
    "id": "kQU9M95yIuI3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\r\n"
     ]
    }
   ],
   "source": [
    "#!wget https://www-users.york.ac.uk/~waps101/PADL/LeNet_weights.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:22:04.010902Z",
     "start_time": "2024-04-30T13:22:03.956444Z"
    },
    "id": "XnGG-tcblF-U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=5 * 5 * 16, out_features=120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = LeNet()\n",
    "model.load_state_dict(\n",
    "    torch.load(\"data/LeNet_weights.pkl\", map_location=torch.device(device))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKaDK8OPvCt6"
   },
   "source": [
    "You now have a network that is good at classifying the MNIST digit dataset. Let's take the first test image, run it through the network and check its classification and how confident it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:29:30.037810Z",
     "start_time": "2024-04-30T13:29:29.988233Z"
    },
    "id": "s3HeH0AdoE84"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = datasets.MNIST(\n",
    "    root=\"data\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "# Extract the first test image (correct class=7)\n",
    "image, label = test_data[0]\n",
    "# Make a batch of just this image\n",
    "images = image.unsqueeze(0)\n",
    "# Run image through pretrained network\n",
    "output = model(images)\n",
    "# Find highest probability class\n",
    "pred_y = torch.argmax(output, 1)\n",
    "# Convert logits to probabilities\n",
    "probs = nn.functional.softmax(output, dim=1)\n",
    "\n",
    "figure = plt.figure(figsize=(5, 5))\n",
    "plt.title(\n",
    "    \"Predicted class: {}, confidence: {:.4f}%\".format(\n",
    "        pred_y[0], probs[0, pred_y[0]] * 100\n",
    "    )\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image[0, :], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl_ouEa8vOTy"
   },
   "source": [
    "It's very confident that this is a seven!\n",
    "\n",
    "**To do**: You now need to solve an optimisation problem to find the perturbation $\\mathbf{r}$ to the input image $\\mathbf{x}$ such that $\\mathbf{x}+\\mathbf{r}$ is classified as a zero instead of a seven. The loss that your optimisation will seek to minimise is a sum of two losses:\n",
    "\n",
    "1. Cross entropy loss with the incorrect label of `[0]`.\n",
    "2. A loss to keep the magnitude of the perturbation small (i.e. to change the image as little as possible). Using the sum of the squared value of all elements of $\\mathbf{r}$ works ok for this.\n",
    "\n",
    "The loss you will optimise should be the sum of these two losses with the second weighted by a parameter $c$. This parameter trades off how much it modifies the image against how much it can change the classification result. Start off with $c=1.0$.\n",
    "\n",
    "The only thing you are optimising is $\\mathbf{r}$. Look back at the week 1 practical if you can't remember how to use PyTorch to directly optimise a variable. Initialise $\\mathbf{r}$ as all zeros.\n",
    "\n",
    "During the optimisation, print out the value of the two losses. The magnitude of the perturbation will start off as zero so must increase in order to decrease the classification loss. You might need to play with the value of $c$ to get a desirable result. Also print out the current classification result so you can see when it switches its mind to class zero.\n",
    "\n",
    "Once you think you have a good result, visualise the perturbed image and also the perturbation on its own. You can also try different incorrect classes. Can you get it to change its mind with a less obvious perturbation for other classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:52:26.158388Z",
     "start_time": "2024-04-30T13:52:26.061486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class in epoch 0: 7\n",
      "classification loss in epoch 0: 13.218868255615234\n",
      "magnitude loss in epoch 0: 0.0\n",
      "------------------------------\n",
      "Predicted class in epoch 1: 7\n",
      "classification loss in epoch 1: 11.913799285888672\n",
      "magnitude loss in epoch 1: 0.03919997066259384\n",
      "------------------------------\n",
      "Predicted class in epoch 2: 7\n",
      "classification loss in epoch 2: 10.329822540283203\n",
      "magnitude loss in epoch 2: 0.14542986452579498\n",
      "------------------------------\n",
      "Predicted class in epoch 3: 7\n",
      "classification loss in epoch 3: 8.441080093383789\n",
      "magnitude loss in epoch 3: 0.31305184960365295\n",
      "------------------------------\n",
      "Predicted class in epoch 4: 7\n",
      "classification loss in epoch 4: 6.2967529296875\n",
      "magnitude loss in epoch 4: 0.5370460152626038\n",
      "------------------------------\n",
      "Predicted class in epoch 5: 7\n",
      "classification loss in epoch 5: 4.2162299156188965\n",
      "magnitude loss in epoch 5: 0.8146558403968811\n",
      "------------------------------\n",
      "Predicted class in epoch 6: 2\n",
      "classification loss in epoch 6: 3.2360646724700928\n",
      "magnitude loss in epoch 6: 1.1305513381958008\n",
      "------------------------------\n",
      "Predicted class in epoch 7: 2\n",
      "classification loss in epoch 7: 2.8753437995910645\n",
      "magnitude loss in epoch 7: 1.4164481163024902\n",
      "------------------------------\n",
      "Predicted class in epoch 8: 2\n",
      "classification loss in epoch 8: 2.349276542663574\n",
      "magnitude loss in epoch 8: 1.6626737117767334\n",
      "------------------------------\n",
      "Predicted class in epoch 9: 2\n",
      "classification loss in epoch 9: 1.6990958452224731\n",
      "magnitude loss in epoch 9: 1.8774160146713257\n",
      "------------------------------\n",
      "Predicted class in epoch 10: 2\n",
      "classification loss in epoch 10: 1.075465202331543\n",
      "magnitude loss in epoch 10: 2.0671589374542236\n",
      "------------------------------\n",
      "Predicted class in epoch 11: 0\n",
      "classification loss in epoch 11: 0.613562822341919\n",
      "magnitude loss in epoch 11: 2.23258638381958\n",
      "------------------------------\n",
      "Predicted class in epoch 12: 0\n",
      "classification loss in epoch 12: 0.3477647006511688\n",
      "magnitude loss in epoch 12: 2.3684630393981934\n",
      "------------------------------\n",
      "Predicted class in epoch 13: 0\n",
      "classification loss in epoch 13: 0.21782653033733368\n",
      "magnitude loss in epoch 13: 2.4689760208129883\n",
      "------------------------------\n",
      "Predicted class in epoch 14: 0\n",
      "classification loss in epoch 14: 0.1564599871635437\n",
      "magnitude loss in epoch 14: 2.5319929122924805\n",
      "------------------------------\n",
      "Predicted class in epoch 15: 0\n",
      "classification loss in epoch 15: 0.1252458095550537\n",
      "magnitude loss in epoch 15: 2.5589725971221924\n",
      "------------------------------\n",
      "Predicted class in epoch 16: 0\n",
      "classification loss in epoch 16: 0.10684390366077423\n",
      "magnitude loss in epoch 16: 2.5535080432891846\n",
      "------------------------------\n",
      "Predicted class in epoch 17: 0\n",
      "classification loss in epoch 17: 0.09418607503175735\n",
      "magnitude loss in epoch 17: 2.520169258117676\n",
      "------------------------------\n",
      "Predicted class in epoch 18: 0\n",
      "classification loss in epoch 18: 0.08473523706197739\n",
      "magnitude loss in epoch 18: 2.463813304901123\n",
      "------------------------------\n",
      "Predicted class in epoch 19: 0\n",
      "classification loss in epoch 19: 0.07793360203504562\n",
      "magnitude loss in epoch 19: 2.389199733734131\n",
      "------------------------------\n",
      "Predicted class in epoch 20: 0\n",
      "classification loss in epoch 20: 0.07417155802249908\n",
      "magnitude loss in epoch 20: 2.300792694091797\n",
      "------------------------------\n",
      "Predicted class in epoch 21: 0\n",
      "classification loss in epoch 21: 0.07450567185878754\n",
      "magnitude loss in epoch 21: 2.2026820182800293\n",
      "------------------------------\n",
      "Predicted class in epoch 22: 0\n",
      "classification loss in epoch 22: 0.08079975098371506\n",
      "magnitude loss in epoch 22: 2.0985937118530273\n",
      "------------------------------\n",
      "Predicted class in epoch 23: 0\n",
      "classification loss in epoch 23: 0.09604707360267639\n",
      "magnitude loss in epoch 23: 1.9919734001159668\n",
      "------------------------------\n",
      "Predicted class in epoch 24: 0\n",
      "classification loss in epoch 24: 0.12431161850690842\n",
      "magnitude loss in epoch 24: 1.8861507177352905\n",
      "------------------------------\n",
      "Predicted class in epoch 25: 0\n",
      "classification loss in epoch 25: 0.16888585686683655\n",
      "magnitude loss in epoch 25: 1.7845524549484253\n",
      "------------------------------\n",
      "Predicted class in epoch 26: 0\n",
      "classification loss in epoch 26: 0.2270289808511734\n",
      "magnitude loss in epoch 26: 1.69082510471344\n",
      "------------------------------\n",
      "Predicted class in epoch 27: 0\n",
      "classification loss in epoch 27: 0.2842819094657898\n",
      "magnitude loss in epoch 27: 1.6085665225982666\n",
      "------------------------------\n",
      "Predicted class in epoch 28: 0\n",
      "classification loss in epoch 28: 0.31911683082580566\n",
      "magnitude loss in epoch 28: 1.5404950380325317\n",
      "------------------------------\n",
      "Predicted class in epoch 29: 0\n",
      "classification loss in epoch 29: 0.31950873136520386\n",
      "magnitude loss in epoch 29: 1.4875551462173462\n",
      "------------------------------\n",
      "Predicted class in epoch 30: 0\n",
      "classification loss in epoch 30: 0.29207155108451843\n",
      "magnitude loss in epoch 30: 1.4486970901489258\n",
      "------------------------------\n",
      "Predicted class in epoch 31: 0\n",
      "classification loss in epoch 31: 0.2534758448600769\n",
      "magnitude loss in epoch 31: 1.4213826656341553\n",
      "------------------------------\n",
      "Predicted class in epoch 32: 0\n",
      "classification loss in epoch 32: 0.2175292819738388\n",
      "magnitude loss in epoch 32: 1.402390480041504\n",
      "------------------------------\n",
      "Predicted class in epoch 33: 0\n",
      "classification loss in epoch 33: 0.1904430389404297\n",
      "magnitude loss in epoch 33: 1.3885340690612793\n",
      "------------------------------\n",
      "Predicted class in epoch 34: 0\n",
      "classification loss in epoch 34: 0.17298147082328796\n",
      "magnitude loss in epoch 34: 1.377102017402649\n",
      "------------------------------\n",
      "Predicted class in epoch 35: 0\n",
      "classification loss in epoch 35: 0.1637062281370163\n",
      "magnitude loss in epoch 35: 1.3660222291946411\n",
      "------------------------------\n",
      "Predicted class in epoch 36: 0\n",
      "classification loss in epoch 36: 0.16081704199314117\n",
      "magnitude loss in epoch 36: 1.3538718223571777\n",
      "------------------------------\n",
      "Predicted class in epoch 37: 0\n",
      "classification loss in epoch 37: 0.16277144849300385\n",
      "magnitude loss in epoch 37: 1.3398202657699585\n",
      "------------------------------\n",
      "Predicted class in epoch 38: 0\n",
      "classification loss in epoch 38: 0.1683511883020401\n",
      "magnitude loss in epoch 38: 1.3235429525375366\n",
      "------------------------------\n",
      "Predicted class in epoch 39: 0\n",
      "classification loss in epoch 39: 0.17656072974205017\n",
      "magnitude loss in epoch 39: 1.3051292896270752\n",
      "------------------------------\n",
      "Predicted class in epoch 40: 0\n",
      "classification loss in epoch 40: 0.186517596244812\n",
      "magnitude loss in epoch 40: 1.2849946022033691\n",
      "------------------------------\n",
      "Predicted class in epoch 41: 0\n",
      "classification loss in epoch 41: 0.1973736435174942\n",
      "magnitude loss in epoch 41: 1.2637983560562134\n",
      "------------------------------\n",
      "Predicted class in epoch 42: 0\n",
      "classification loss in epoch 42: 0.20828117430210114\n",
      "magnitude loss in epoch 42: 1.2423686981201172\n",
      "------------------------------\n",
      "Predicted class in epoch 43: 0\n",
      "classification loss in epoch 43: 0.2183871567249298\n",
      "magnitude loss in epoch 43: 1.2216215133666992\n",
      "------------------------------\n",
      "Predicted class in epoch 44: 0\n",
      "classification loss in epoch 44: 0.22685930132865906\n",
      "magnitude loss in epoch 44: 1.2024801969528198\n",
      "------------------------------\n",
      "Predicted class in epoch 45: 0\n",
      "classification loss in epoch 45: 0.23292753100395203\n",
      "magnitude loss in epoch 45: 1.1857938766479492\n",
      "------------------------------\n",
      "Predicted class in epoch 46: 0\n",
      "classification loss in epoch 46: 0.2359655499458313\n",
      "magnitude loss in epoch 46: 1.1722511053085327\n",
      "------------------------------\n",
      "Predicted class in epoch 47: 0\n",
      "classification loss in epoch 47: 0.23559856414794922\n",
      "magnitude loss in epoch 47: 1.162300705909729\n",
      "------------------------------\n",
      "Predicted class in epoch 48: 0\n",
      "classification loss in epoch 48: 0.23181678354740143\n",
      "magnitude loss in epoch 48: 1.1560869216918945\n",
      "------------------------------\n",
      "Predicted class in epoch 49: 0\n",
      "classification loss in epoch 49: 0.2250330001115799\n",
      "magnitude loss in epoch 49: 1.1534216403961182\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "c = 0.5\n",
    "desired_label = torch.tensor(0).unsqueeze(0)\n",
    "x = image\n",
    "r = torch.zeros((28, 28), requires_grad=True)\n",
    "classification_loss = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam([r], lr=0.01)\n",
    "\n",
    "\n",
    "def magnitude_loss(perturbation):\n",
    "    return torch.sum(torch.flatten(perturbation).pow(2))\n",
    "\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    modified_image = image + r\n",
    "    output = model(modified_image.unsqueeze(0))\n",
    "    print(f\"Predicted class in epoch {i}: {torch.argmax(output, 1).item()}\")\n",
    "    optim.zero_grad()\n",
    "    loss_1 = classification_loss(output, desired_label)\n",
    "    loss_2 = magnitude_loss(r) * c\n",
    "    loss = loss_1 + loss_2\n",
    "    print(f\"classification loss in epoch {i}: {loss_1.item()}\")\n",
    "    print(f\"magnitude loss in epoch {i}: {loss_2.item()}\")\n",
    "    print(\"------------------------------\")\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:53:53.773267Z",
     "start_time": "2024-04-30T13:53:53.580471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Perturbation')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow((image + r.detach().numpy()).squeeze(0), cmap=\"gray\")\n",
    "ax[0].set_title(\"Image with perturbation\")\n",
    "ax[1].imshow(r.detach().numpy(), cmap=\"gray\")\n",
    "ax[1].set_title(\"Perturbation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAotwPrSiZPh"
   },
   "source": [
    "## 2. GANs\n",
    "\n",
    "We're going to train a GAN using the same Fashion MNIST dataset as last week. We'll use the built-in dataloader this time. A few things to note:\n",
    "1. for a GAN, we only need a training set (a validation set doesn't really make any sense in the context of a GAN)\n",
    "2. the dataset is originally 28 x 28 images, I've padded this to 32 x 32 using the `transforms.CenterCrop` transform (it made it easier to reuse the DCGAN architecture later).\n",
    "3. the GAN trains better if you normalise your image data to be scaled between -1 and 1 (rather than 0 and 1). This is done with `transforms.Normalize`.\n",
    "\n",
    "Let's start by importing everything we need, setting up some parameters and setting up the data loader.\n",
    "\n",
    "Note: training the GAN is slow. You might want to choose Edit -> Notebook settings -> Hardware accelerator -> GPU now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phhcbAUupb0o"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define some parameters\n",
    "batch_size = 100\n",
    "nz = 100  # Size of z latent vector (i.e. size of generator input)\n",
    "ngf = 64  # Size of feature maps in generator\n",
    "ndf = 64  # Size of feature maps in discriminator\n",
    "num_epochs = 5  # Number of training epochs\n",
    "lr = 0.0002  # Learning rate for optimizers\n",
    "beta1 = 0.5  # Beta1 hyperparam for Adam optimizers\n",
    "\n",
    "# Set up the dataset and dataloader\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.CenterCrop(32), transforms.Normalize(0.5, 0.5)]\n",
    ")\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, transform=transform, download=True\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SL-pljea7034"
   },
   "source": [
    "As last week, let's grab a batch of images and visualise the first 25 images. I've negated the image brightness to put the images back to how they originally looked - this is a nicer way to visualise them. You can use this code as a starting point for the visualisation tasks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRTkSrJbrDw5"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(dataloader))\n",
    "\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(cols * rows):\n",
    "    figure.add_subplot(rows, cols, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(0.5 - 0.5 * images[i, :].squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LZmBr9Z8HeB"
   },
   "source": [
    "### Generator architecture\n",
    "\n",
    "I have roughly followed the DCGAN architecture. The Generator takes as input a latent (`z`) vector which has `nz` dimensions. Via an expansive network with transposed convolutions, it converts this into a 32 x 32 image. To map the final output to the range -1..1 we use the Tanh activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuimGmSUsFlz"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z of size B x nz x 1 x 1, we put this directly into a transposed convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # Size: B x (ngf*4) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # Size: B x (ngf*2) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # Size: B x (ngf) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf, 1, 4, 2, 1, bias=False),\n",
    "            # Size: B x 1 x 32 x 32\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "netG = Generator()\n",
    "netG = netG.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axgew88Y9XpV"
   },
   "source": [
    "### Discriminator architecture\n",
    "\n",
    "The discriminator is a conventional binary classification CNN: it takes an image as input and outputs the probability that the image is real. I've again followed the DCGAN architecture which uses something you haven't seen before: LeakyReLU. This is a variant on ReLU where negative values are allowed to \"leak\" through, albeit scaled down. Everything else you should have seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R61sEPaAtzoZ"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # state size. 1 x 32 x 32\n",
    "            nn.Conv2d(1, ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 16 x 16\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 8 x 8\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "netD = Discriminator()\n",
    "netD = netD.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GB3v9Hbe-Ake"
   },
   "source": [
    "### GAN training\n",
    "\n",
    "We're now ready to train our GAN. The training loop for a GAN is pretty complicated so look through the following code carefully and read the comments. You may want to refer to the fifth video lecture for this week to help understand it. You can try running it for a while to train your own GAN but it's slow and below I provide some pretrained weights. Note: even though the data loader is returning labels, we're not using them here. A GAN doesn't need labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBTE3I2Xuu4b"
   },
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, (images, labels) in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_images = images.to(device)\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_images).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        z = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(z)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print(\n",
    "                \"[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f\"\n",
    "                % (\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    i,\n",
    "                    len(dataloader),\n",
    "                    errD.item(),\n",
    "                    errG.item(),\n",
    "                    D_x,\n",
    "                    D_G_z1,\n",
    "                    D_G_z2,\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmhjThoF_PnR"
   },
   "source": [
    "### Visualise GAN output\n",
    "\n",
    "**To do**:\n",
    "\n",
    "Generate some random latent codes, pass them through the generator to get images and then visualise them like we visualised the random training images above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7Y8sn8k-5DP"
   },
   "source": [
    "### Loading pretrained weights\n",
    "\n",
    "The above training loop is starting to take quite a lot of time, even using a GPU. 5 epochs is not enough for good results. So I've pretrained a network for you that I trained for 100 epochs. Download my pretrained weights and load them into your network, then try running your visualisation code again. Are the results noticably better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvKWGelT5V3I"
   },
   "outputs": [],
   "source": [
    "#!wget https://www-users.york.ac.uk/~waps101/PADL/netG.pkl\n",
    "netG.load_state_dict(torch.load(\"netG.pkl\", map_location=torch.device(device)))\n",
    "netG.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNFZovmchTqE"
   },
   "source": [
    "## Latent space interpolation\n",
    "\n",
    "One of the interesting things about GANs is that the latent space of the generator provides a set of parameters that can be manipulated to change the appearance of the image in a smooth way. Walking around in the latent space results in an image that gradually varies hopefully remaining plausible all the time. The easiest way try this out is by linearly interpolating between two samples.\n",
    "\n",
    "**To do**:\n",
    "\n",
    "Write some code that starts by generating two random latent codes, `z1` and `z2`. Now create a batch of 9 latent codes that linearly interpolates between them so that the first element in the batch is equal to `z1`, the ninth is equal to `z2` and the fifth (i.e. the middle element) is equal to `0.5*z1 + 0.5*z2`. Pass the batch of latent codes through your generator (remember to put the generator in eval mode first with `netG.eval()` so that the batchnorm layers use the learnt means/stds). Now display the resulting images (adapt the code we've used previously for visualing images from a batch). You should see a gradual transition from one image to the other and the intermediates should look reasonable (although it's hard to interpolate from a handbag to a pair of trousers!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILxrcz8JyFpu"
   },
   "source": [
    "## 3. Play with a pretrained diffusion model\n",
    "\n",
    "First we need to install some dependencies and import. This takes a few minutes to run so take a break while it's running!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCXcNWB1yTVl"
   },
   "outputs": [],
   "source": [
    "!pip install \"jax[cuda12_local]==0.4.23\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "!pip install diffusers==0.11.1\n",
    "!pip install transformers scipy ftfy accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NIJZo4P7yte"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMmZ7gMU4-WQ"
   },
   "source": [
    "Now it's time to play! This diffusion implementation comes with a nice end to end text-to-image pipeline. You simply need to provide a text prompt and it will generate an image. You will get a different result every time as the starting random noise will be different. Experiment with different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzeSPH5NzAwp"
   },
   "outputs": [],
   "source": [
    "prompt = \"a photograph of an astronaut riding a horse\"\n",
    "image = pipe(prompt).images[0]  # image here is in PIL format\n",
    "\n",
    "# directly display the generated image\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSemcECCzt0f"
   },
   "source": [
    "`pipe` can take various other option parameters. Try playing with `num_inference_steps` which controls how many diffusion steps are used (fewer is faster but lower quality), `height` and `width` which control the size of the output and `guidance_scale` which controls how much weight it gives to your text prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2qKAu26xxqE"
   },
   "source": [
    "Let's now dig a little deeper and see a denoising loop in action. First, some setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgMENJvWx6cs"
   },
   "outputs": [],
   "source": [
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel\n",
    "from diffusers import LMSDiscreteScheduler\n",
    "\n",
    "# 1. Load the autoencoder model which will be used to decode the latents into image space.\n",
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\")\n",
    "\n",
    "# 2. Load the tokenizer and text encoder to tokenize and encode the text.\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "\n",
    "# 3. The UNet model for generating the latents.\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\"\n",
    ")\n",
    "\n",
    "scheduler = LMSDiscreteScheduler.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\"\n",
    ")\n",
    "\n",
    "vae = vae.to(device)\n",
    "text_encoder = text_encoder.to(device)\n",
    "unet = unet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrSs-OIUyHmr"
   },
   "source": [
    "Prepare our inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WOMLHyTyJDJ"
   },
   "outputs": [],
   "source": [
    "prompt = [\"a photograph of an astronaut riding a horse\"]\n",
    "\n",
    "height = 512  # default height of Stable Diffusion\n",
    "width = 512  # default width of Stable Diffusion\n",
    "\n",
    "num_inference_steps = 100  # Number of denoising steps\n",
    "\n",
    "guidance_scale = 7.5  # Scale for classifier-free guidance\n",
    "\n",
    "generator = torch.manual_seed(32)  # Seed generator to create the inital latent noise\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "text_input = tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n",
    "\n",
    "max_length = text_input.input_ids.shape[-1]\n",
    "uncond_input = tokenizer(\n",
    "    [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
    ")\n",
    "with torch.no_grad():\n",
    "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\n",
    "\n",
    "text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
    "\n",
    "# Random initial latents\n",
    "latents = torch.randn(\n",
    "    (batch_size, unet.in_channels, height // 8, width // 8),\n",
    "    generator=generator,\n",
    ")\n",
    "latents = latents.to(device)\n",
    "\n",
    "scheduler.set_timesteps(num_inference_steps)\n",
    "latents = latents * scheduler.init_noise_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-IVgoqgygtg"
   },
   "source": [
    "Now we are ready to run the denoising loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSBWEXT3yjzW"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for t in tqdm(scheduler.timesteps):\n",
    "    # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
    "    latent_model_input = torch.cat([latents] * 2)\n",
    "\n",
    "    latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
    "\n",
    "    # predict the noise residual\n",
    "    with torch.no_grad():\n",
    "        noise_pred = unet(\n",
    "            latent_model_input, t, encoder_hidden_states=text_embeddings\n",
    "        ).sample\n",
    "\n",
    "    # perform guidance\n",
    "    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "    noise_pred = noise_pred_uncond + guidance_scale * (\n",
    "        noise_pred_text - noise_pred_uncond\n",
    "    )\n",
    "\n",
    "    # compute the previous noisy sample x_t -> x_t-1\n",
    "    latents = scheduler.step(noise_pred, t, latents).prev_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oko7UL2Lyx1H"
   },
   "source": [
    "Visualise the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ltcfi1Wyopq"
   },
   "outputs": [],
   "source": [
    "# scale and decode the image latents with vae\n",
    "latents = 1 / 0.18215 * latents\n",
    "\n",
    "with torch.no_grad():\n",
    "    image = vae.decode(latents).sample\n",
    "\n",
    "image = (image / 2 + 0.5).clamp(0, 1)\n",
    "image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "images = (image * 255).round().astype(\"uint8\")\n",
    "pil_images = [Image.fromarray(image) for image in images]\n",
    "pil_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_4tcmKUysh6"
   },
   "source": [
    "**To do**: At any point in the loop, you could convert the noisy latents to an image using the VAE decoder. Try this out. You should be able to visualise the result gradually transitioning from noise to the final image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MU4kMgkMAklr"
   },
   "source": [
    "## 4. Create a conditional GAN (highly recommended for MEng students)\n",
    "\n",
    "I would now like you to extend the GAN created above to make it into a conditional GAN. This means that the generator takes both a z latent vector and also a class label and generates an image of the appropriate class. The discriminator takes an image plus the class label and returns the probability that this is a real image of that class. There are many ways you could engineer the generator and discriminator architectures to take labels as input but here is my suggestion:\n",
    "- Use a `torch.nn.Embedding` layer to turn the class label into a feature vector. A dimensionality of 50 for this feature vector works well.\n",
    "- In the generator you can then just concatenate this embedding with the `z` vector and feed it into the same generator architecture as above.\n",
    "- In the discriminator, use another linear layer to transform the embedding up to size 32 x 32. You can then just concatenate this as an additional channel to the image that you pass into the same architecture as above (just with two input channels rather than 1).\n",
    "- The training loop is very similar to above but now you pass the real labels along with the real images to the discriminator. When you create a random batch of fake images, you need to generate some random labels. These should also be passed to the discriminator.\n",
    "\n",
    "Once you get it to train, try visualing random output for each class. For example, fix the label to zero then generate 8 images, then repeat for labels 1-9. You should see the right class but random variation within that class when you vary z."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1k9k7H7xuhTflDD-OsxFqg0TFxqGTQBYQ",
     "timestamp": 1714466218267
    },
    {
     "file_id": "1NVr4N7ScgG3gCTx515JbZxsYboB4J04R",
     "timestamp": 1714388768749
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
